{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["IbQAIcjbpMb_","tgFhQ0OD_XEd","hp-BdKGCzvWZ"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4a0aefbffe5141b6b374492b494198f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed0edd78561a457bbf48ee5c63570350","IPY_MODEL_6794a502a0824fc08879851da8666199","IPY_MODEL_1ed610916608489fb50c2e6e59ada334"],"layout":"IPY_MODEL_789a2639c73d4b0ca0f411140effe4c5"}},"ed0edd78561a457bbf48ee5c63570350":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87d033bd09534087ba5c6291bcef2502","placeholder":"​","style":"IPY_MODEL_16985495603c4214ba0a7622b9bbfe0b","value":"tokenizer_config.json: 100%"}},"6794a502a0824fc08879851da8666199":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18643fc2f58641839bb07b14a998e4e6","max":1197,"min":0,"orientation":"horizontal","style":"IPY_MODEL_20b1fef2e3b64c5fb8ff62a9ddc52a25","value":1197}},"1ed610916608489fb50c2e6e59ada334":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbeeb6281e184ca8a81c01ee642310fe","placeholder":"​","style":"IPY_MODEL_fa9b715184684e7484f810b8fa6139b6","value":" 1.20k/1.20k [00:00&lt;00:00, 82.5kB/s]"}},"789a2639c73d4b0ca0f411140effe4c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87d033bd09534087ba5c6291bcef2502":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16985495603c4214ba0a7622b9bbfe0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18643fc2f58641839bb07b14a998e4e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20b1fef2e3b64c5fb8ff62a9ddc52a25":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bbeeb6281e184ca8a81c01ee642310fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa9b715184684e7484f810b8fa6139b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a3367507a3248ceb29d45b85c4ff266":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ce390109f134c64b853655493530e6d","IPY_MODEL_2dfb4968311e40f4a6628fa9aa0f9564","IPY_MODEL_ffcfbf6875ba4a6ba9814a905bf56756"],"layout":"IPY_MODEL_5eeb8140039642a3b3c2e6fa280a39cf"}},"9ce390109f134c64b853655493530e6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_993d7aaa1aa94491ad27a589090a6b78","placeholder":"​","style":"IPY_MODEL_5826fae13890497cb331f7a2daf405a7","value":"vocab.txt: 100%"}},"2dfb4968311e40f4a6628fa9aa0f9564":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8292e039569e40c3b39c085ed8064f16","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8b270407ee147a1884a0624eb6f4b76","value":213450}},"ffcfbf6875ba4a6ba9814a905bf56756":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_031b700f87e549d99ca5667a3f98a1bb","placeholder":"​","style":"IPY_MODEL_0e9d8616d8bf4ef8aeb58288e2f7416b","value":" 213k/213k [00:00&lt;00:00, 1.02MB/s]"}},"5eeb8140039642a3b3c2e6fa280a39cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"993d7aaa1aa94491ad27a589090a6b78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5826fae13890497cb331f7a2daf405a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8292e039569e40c3b39c085ed8064f16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8b270407ee147a1884a0624eb6f4b76":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"031b700f87e549d99ca5667a3f98a1bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e9d8616d8bf4ef8aeb58288e2f7416b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07fb49251b5249f78a2d44a9d41a3bc0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eff87d581df147a19a6f75cd7472c3ff","IPY_MODEL_bef1e340e3ff4515a05e7f5a5c670aa3","IPY_MODEL_5fc5a66f04714bdeb05659b91972b1f7"],"layout":"IPY_MODEL_1129749614d24be48d51bbe7f886dbe9"}},"eff87d581df147a19a6f75cd7472c3ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67d6f30321c64a38a34a90a32cdccac3","placeholder":"​","style":"IPY_MODEL_eb7ef4154f3b48f7b74ae765bc7de578","value":"tokenizer.json: 100%"}},"bef1e340e3ff4515a05e7f5a5c670aa3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eda29aa162f447c1b2b4b333ad4a2645","max":669021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c78387bb1bf4e308f76983f33ff5819","value":669021}},"5fc5a66f04714bdeb05659b91972b1f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_260c3fadcf1f49f4b3f7004c525bb951","placeholder":"​","style":"IPY_MODEL_f22ccb51c5b445048a32a6e836664f00","value":" 669k/669k [00:00&lt;00:00, 1.60MB/s]"}},"1129749614d24be48d51bbe7f886dbe9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67d6f30321c64a38a34a90a32cdccac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb7ef4154f3b48f7b74ae765bc7de578":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eda29aa162f447c1b2b4b333ad4a2645":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c78387bb1bf4e308f76983f33ff5819":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"260c3fadcf1f49f4b3f7004c525bb951":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f22ccb51c5b445048a32a6e836664f00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3106d4f8557493d826be5f24462157c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c14b8b67dd0744e68d32b0537a946bfb","IPY_MODEL_fb85071ab8984a6cbe2164231609e69a","IPY_MODEL_93b75e8250574075aec202b5a2d88d94"],"layout":"IPY_MODEL_483888d2f87a4ad7afa34bd3afd0e36e"}},"c14b8b67dd0744e68d32b0537a946bfb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c44886e69a34b42b0c1293bb97b17e2","placeholder":"​","style":"IPY_MODEL_1b2564593a844201bd84f7f6ac7ecc34","value":"special_tokens_map.json: 100%"}},"fb85071ab8984a6cbe2164231609e69a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1fc281fbf9347a99350b66bbe0c3c85","max":125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe5509fc7caf438fa638df682396c8e7","value":125}},"93b75e8250574075aec202b5a2d88d94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3095ff87ac854522bf5b09488b7c9312","placeholder":"​","style":"IPY_MODEL_4d88edf269414f7eae1bc0ed5cb5ab5d","value":" 125/125 [00:00&lt;00:00, 8.44kB/s]"}},"483888d2f87a4ad7afa34bd3afd0e36e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c44886e69a34b42b0c1293bb97b17e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b2564593a844201bd84f7f6ac7ecc34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1fc281fbf9347a99350b66bbe0c3c85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe5509fc7caf438fa638df682396c8e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3095ff87ac854522bf5b09488b7c9312":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d88edf269414f7eae1bc0ed5cb5ab5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a77419dbff2b421198a2234e26a379ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_caad6b0b85984dc8ac010ae5cb658ecb","IPY_MODEL_21cd4d2e51964acc8db62cd77374bdde","IPY_MODEL_154a8998ba1b43139b561642ecc2fbc3"],"layout":"IPY_MODEL_fee3f35440c1441193b345d839406d09"}},"caad6b0b85984dc8ac010ae5cb658ecb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca1b4501411a411cb2231a77016b15cc","placeholder":"​","style":"IPY_MODEL_bddcce0c4da04f8fa8edbb5b14066ce3","value":"Downloading builder script: 100%"}},"21cd4d2e51964acc8db62cd77374bdde":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9d4726cb3d142d99755fa54e6d4e3c3","max":6338,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e33bce963584e028e9aefdd4017d4e2","value":6338}},"154a8998ba1b43139b561642ecc2fbc3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ba43b10023c4fe0b61e2f77a4f1e921","placeholder":"​","style":"IPY_MODEL_6a318b1332254442811d6546577406c9","value":" 6.34k/6.34k [00:00&lt;00:00, 114kB/s]"}},"fee3f35440c1441193b345d839406d09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca1b4501411a411cb2231a77016b15cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bddcce0c4da04f8fa8edbb5b14066ce3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9d4726cb3d142d99755fa54e6d4e3c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e33bce963584e028e9aefdd4017d4e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ba43b10023c4fe0b61e2f77a4f1e921":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a318b1332254442811d6546577406c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# **Optuna para NER**\n","### **Búsqueda de los hiperparámetros más óptimos**\n","\n","Optuna es una biblioteca de Python que permite la optimización automática de hiperparámetros de nuestro modelo.\n","\n","Para cada hiperparámetro definimos un rango de valores de búsqueda y corremos el código para que Optuna nos encuentre la combinación que resulta en el mayor recall."],"metadata":{"id":"Ni3JcsJZo6Jp"}},{"cell_type":"markdown","metadata":{"id":"IbQAIcjbpMb_"},"source":["#Preparacion de Entorno"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":95534,"status":"ok","timestamp":1731292509742,"user":{"displayName":"Lucas De Fino","userId":"17839929889021431258"},"user_tz":180},"id":"oRL-AzKokGE7","outputId":"18f7ae53-906c-4336-8516-54c8c69b223a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd \"/content/drive/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["4a0aefbffe5141b6b374492b494198f8","ed0edd78561a457bbf48ee5c63570350","6794a502a0824fc08879851da8666199","1ed610916608489fb50c2e6e59ada334","789a2639c73d4b0ca0f411140effe4c5","87d033bd09534087ba5c6291bcef2502","16985495603c4214ba0a7622b9bbfe0b","18643fc2f58641839bb07b14a998e4e6","20b1fef2e3b64c5fb8ff62a9ddc52a25","bbeeb6281e184ca8a81c01ee642310fe","fa9b715184684e7484f810b8fa6139b6","9a3367507a3248ceb29d45b85c4ff266","9ce390109f134c64b853655493530e6d","2dfb4968311e40f4a6628fa9aa0f9564","ffcfbf6875ba4a6ba9814a905bf56756","5eeb8140039642a3b3c2e6fa280a39cf","993d7aaa1aa94491ad27a589090a6b78","5826fae13890497cb331f7a2daf405a7","8292e039569e40c3b39c085ed8064f16","f8b270407ee147a1884a0624eb6f4b76","031b700f87e549d99ca5667a3f98a1bb","0e9d8616d8bf4ef8aeb58288e2f7416b","07fb49251b5249f78a2d44a9d41a3bc0","eff87d581df147a19a6f75cd7472c3ff","bef1e340e3ff4515a05e7f5a5c670aa3","5fc5a66f04714bdeb05659b91972b1f7","1129749614d24be48d51bbe7f886dbe9","67d6f30321c64a38a34a90a32cdccac3","eb7ef4154f3b48f7b74ae765bc7de578","eda29aa162f447c1b2b4b333ad4a2645","4c78387bb1bf4e308f76983f33ff5819","260c3fadcf1f49f4b3f7004c525bb951","f22ccb51c5b445048a32a6e836664f00","f3106d4f8557493d826be5f24462157c","c14b8b67dd0744e68d32b0537a946bfb","fb85071ab8984a6cbe2164231609e69a","93b75e8250574075aec202b5a2d88d94","483888d2f87a4ad7afa34bd3afd0e36e","5c44886e69a34b42b0c1293bb97b17e2","1b2564593a844201bd84f7f6ac7ecc34","e1fc281fbf9347a99350b66bbe0c3c85","fe5509fc7caf438fa638df682396c8e7","3095ff87ac854522bf5b09488b7c9312","4d88edf269414f7eae1bc0ed5cb5ab5d"]},"executionInfo":{"elapsed":12481,"status":"ok","timestamp":1731292522212,"user":{"displayName":"Lucas De Fino","userId":"17839929889021431258"},"user_tz":180},"id":"uj4DJWl4uvWz","outputId":"0871323b-15c7-4f81-c961-85cbe8bd61c1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a0aefbffe5141b6b374492b494198f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a3367507a3248ceb29d45b85c4ff266"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/669k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07fb49251b5249f78a2d44a9d41a3bc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3106d4f8557493d826be5f24462157c"}},"metadata":{}}],"source":["from transformers import AutoTokenizer\n","checkpoint = 'dslim/distilbert-ner'\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)"]},{"cell_type":"markdown","metadata":{"id":"tgFhQ0OD_XEd"},"source":["#Data Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_vG8RxA-_esn"},"outputs":[],"source":["label_names = ['O', 'B-PER', 'I-PER', 'B-ARCH', 'I-ARCH', 'B-LOC', 'I-LOC']\n","\n","id2label = {k: v for k, v in enumerate(label_names)}\n","\n","label2id = {v: k for k, v in enumerate(label_names)}"]},{"cell_type":"code","source":["test_archs = [\n","    \"Ste-Geneviéve\", \"Newgate Gaol\", \"Schauspielhaus\", \"Altes Museum\", \"British Museum\", \"Bibliotheque Ste-Geneviéve\", \"Palm House\", \"Gare de I’Est\", \"Streatham Street Flats\", \"Crystal Palace\", \"Bibliotheque Nationale\", \"‘Old English’ country house\", \"Le Raincy church\",\n","    \"Palais de Justice\", \"Galerie des Machines\", \"State Museums\", \"Burgtheater\", \"Swan House\", \"Rijksmuseum\", \"Winn Memorial Library\", \"Neue Hofburg\", \"Casa Vicens\", \"Sagrada Familia\", \"Marshall Field Wholesale Store\", \"Glessner House\", \"Palau Guell\", \"Miller House\",\n","    \"Century Guild Exhibition Stand\", \"Auditorium Building\", \"Walker Warehouse\", \"Oak Park house\", \"Oak Park studio\", \"Wainwright Building\", \"Dooly Block\", \"Bedford Park\", \"Fair Store\", \"Charnley House\", \"Standen\", \"Landesmuseum\", \"Hétel Tassel\", \"Moller House\",\n","    \"Transportation building\", \"Winslow House\", \"Guaranty Building\", \"Hotel Solvay\", \"church of St-Jean-de-Montmartre\", \"Van Eetvelde and his own house\", \"Luxfer Prism offices\", \"Amsterdam Exchange\", \"McAfee House\", \"Francisco Terrace apartments\", \"Heuberg Estate\",\n","    \"Ecole du Sacré Coeur\", \"Maison Carpeaux\", \"Heller and Husser Houses\", \"Sturgis House\", \"Secession Building\", \"Maison du Peuple\", \"Millbank Estate\", \"Glasgow School of Art\", \"The Barn\", \"Majolica House\", \"Humbert de Romans concert hall\", \"Colonia Guell\", \"Rufer House\",\n","    \"Goldman and Salatsch facade\", \"Broadleys\", \"Castel Henriette\", \"Ernst Ludwig House\", \"Schlesinger and Mayer department store\", \"Café Museum\", \"Heller and Husser Houses\", \"The Orchard\", \"Warren house\", \"House for an Art-lover\", \"Dana House\", \"Heurtley House\",\n","    \"Avenue Wagram\", \"pavilion for the Exhibition of Decorative Arts\", \"apartment building in the Rue Franklin\", \"Wertheim store\", \"Larkin Building\", \"Post Office Savings Bank\", \"Purkersdorf Sanatorium\", \"Grand Ducal School of Arts and Crafts\", \"Dumont Theatre\",\n","    \"Martin House\", \"Willow Tea Rooms\", \"Unity Temple\", \"Palais Stoclet\", \"Hardy House\", \"Nashdom\", \"Robie House\", \"Casa Mila\", \"Tietz department store\", \"Avery Coonley House\", \"American Bar\", \"hotel at Campo de’ Fiori\", \"Steiner House\", \"Viceroy’s House\",  \"Tristan Tzara house\",\n","    \"apartment block completed in Rue Vavin\", \"Central Station\", \"Monza Cemetery\", \"Leipzig Steel Pavilion\", \"Jahrhunderthalle\", \"Glass Pavilion\", \"Werkbund Theatre\", \"Midway Gardens\", \"Citta Nuova\", \"Twin Airship Hangars\", \"Fiat Works\", \"Hotel Imperial\",\"Villa on the Lido\"\n","    ]"],"metadata":{"id":"qRBzUEYMiBYM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YcOfgsvG_gSr"},"outputs":[],"source":["def read_data(file_name):\n","    data = json.load(open(file_name,'r'))\n","\n","    new_data = []\n","\n","    for line in data[\"annotations\"]:\n","        text = line[0]\n","        for arch in test_archs:\n","          if arch in text:\n","            continue\n","        entities = line[1][\"entities\"]\n","        sentences = line[0].split(\".\")\n","\n","        entities_list = {\"PER\": [], \"LOC\": [], \"ARCH\": []}\n","        for start, end, label in entities:\n","            entities_list[label].append(text[start:end])\n","\n","        for sentence in sentences:\n","            sentence = sentence.strip()\n","            new_data_line = [\"\", {\"entities\": []}]\n","            for key, entities in entities_list.items():\n","                for ent in entities:\n","                    if ent in sentence:\n","                        if new_data_line[0] == \"\":\n","                            new_data_line[0] = sentence.translate(str.maketrans('', '', string.punctuation))\n","                        curent_ents = \" \".join([current_ent for current_ent, label in new_data_line[1][\"entities\"]])\n","                        if ent not in curent_ents:\n","                            new_data_line[1][\"entities\"].append((ent.strip(), key))\n","            if new_data_line[0] != \"\":\n","                new_data.append(new_data_line)\n","    return new_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mHe2j3Nn_i-M"},"outputs":[],"source":["def tokenize_data(data):\n","    tokenize_data = []\n","\n","    for line in data:\n","        text = line[0]\n","        entities = line[1][\"entities\"]\n","\n","        tokens = tokenizer(text, return_offsets_mapping=True)\n","\n","        labels = [0] * len(tokens.tokens())\n","        labels[0] = -100\n","        labels[-1] = -100\n","\n","        for ent, label in entities:\n","            start = text.find(ent)\n","            end = start + len(ent)\n","            for idx, (token_start, token_end) in enumerate(tokens[\"offset_mapping\"]):\n","                if token_start >= start and token_end <= end:\n","                    if token_start == start:\n","                        key_label = f\"B-{label}\"\n","                        labels[idx] = label2id[key_label]\n","                    else:\n","                        key_label = f\"I-{label}\"\n","                        labels[idx] = label2id[key_label]\n","\n","        input_ids = tokens[\"input_ids\"]\n","        attention_mask = tokens[\"attention_mask\"]\n","        tokenize_data.append({\n","            \"input_ids\": input_ids,\n","            \"attention_mask\": attention_mask,\n","            \"labels\": labels\n","        })\n","\n","    return tokenize_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xtED0Vb__mJr"},"outputs":[],"source":["folder_path = \"/content/drive/MyDrive/ARCHITECTURE_NER/NER/annotations_dataset\"\n","\n","general_data = []\n","\n","for file_name in os.listdir(folder_path):\n","    if file_name.endswith(\".json\"):\n","        file_path = os.path.join(folder_path, file_name)\n","        data = read_data(file_path)\n","        general_data += data\n","\n","tokenized_data = tokenize_data(general_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":989,"status":"ok","timestamp":1731552497127,"user":{"displayName":"Lucas De Fino","userId":"17839929889021431258"},"user_tz":180},"id":"wwrry5li_pwC","outputId":"14f21267-23ec-45f4-a9f4-c0c7e99a1274"},"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 2320\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 581\n","    })\n","})\n"]}],"source":["dataset = Dataset.from_list(tokenized_data)\n","split_data = dataset.train_test_split(test_size=0.2, seed=1234)\n","dataset_dict = DatasetDict({\n","    'train': split_data['train'],\n","    'validation': split_data['test']\n","})\n","\n","print(dataset_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":935,"status":"ok","timestamp":1731552503287,"user":{"displayName":"Lucas De Fino","userId":"17839929889021431258"},"user_tz":180},"id":"VWuGMzK5CK7Y","outputId":"c5f02879-4a2e-4c86-f469-0e89569a4150"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train labels:\n","{'O': 68902, 'B-PER': 2776, 'I-PER': 5169, 'B-ARCH': 892, 'I-ARCH': 3201, 'B-LOC': 1042, 'I-LOC': 1109}\n","\n","Validation labels:\n","{'O': 16931, 'B-PER': 706, 'I-PER': 1227, 'B-ARCH': 195, 'I-ARCH': 695, 'B-LOC': 231, 'I-LOC': 241}\n"]}],"source":["labels_count = {v: 0 for k, v in enumerate(label_names)}\n","\n","labels_count_2 = {v: 0 for k, v in enumerate(label_names)}\n","\n","for row in dataset_dict['train']:\n","  for label in row['labels']:\n","    if label != -100:\n","      labels_count[id2label[label]] += 1\n","\n","for row in dataset_dict['validation']:\n","  for label in row['labels']:\n","    if label != -100:\n","      labels_count_2[id2label[label]] += 1\n","\n","print(\"Train labels:\")\n","print(labels_count)\n","print(\"\\nValidation labels:\")\n","print(labels_count_2)"]},{"cell_type":"markdown","metadata":{"id":"hp-BdKGCzvWZ"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q9xKC6at8Ved"},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XTZARmuFCAtQ"},"outputs":[],"source":["def precision_calculator(pred_labels: list[list[int]], true_labels: list[list[int]], entities_to_consider: list[int]) -> float:\n","    true_positives = 0\n","    false_positives = 0\n","\n","    for pred_label, true_label in zip(pred_labels, true_labels):\n","        for pred, true in zip(pred_label, true_label):\n","            if pred == -100 or true == -100:\n","                continue\n","\n","            if pred in entities_to_consider:\n","                if true in entities_to_consider:\n","                    true_positives += 1\n","                else:\n","                    false_positives += 1\n","\n","    if true_positives + false_positives == 0:\n","        return 0.0\n","\n","    return true_positives / (true_positives + false_positives)\n","\n","def recall_calculator(pred_labels: list[list[int]], true_labels: list[list[int]], entities_to_consider: list[int]) -> float:\n","    true_positives = 0\n","    false_negatives = 0\n","\n","    for pred_label, true_label in zip(pred_labels, true_labels):\n","        for pred, true in zip(pred_label, true_label):\n","            if pred == -100 or true == -100:\n","                continue\n","\n","            if true in entities_to_consider:\n","                if pred in entities_to_consider:\n","                    true_positives += 1\n","                else:\n","                    false_negatives += 1\n","\n","    if true_positives + false_negatives == 0:\n","        return 0.0\n","\n","    return true_positives / (true_positives + false_negatives)\n","\n","def f1_score_calculator(precision, recall) -> float:\n","    if precision + recall == 0:\n","        return 0.0\n","\n","    return 2 * (precision * recall) / (precision + recall)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SUETmPzl8Vee","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["a77419dbff2b421198a2234e26a379ec","caad6b0b85984dc8ac010ae5cb658ecb","21cd4d2e51964acc8db62cd77374bdde","154a8998ba1b43139b561642ecc2fbc3","fee3f35440c1441193b345d839406d09","ca1b4501411a411cb2231a77016b15cc","bddcce0c4da04f8fa8edbb5b14066ce3","d9d4726cb3d142d99755fa54e6d4e3c3","9e33bce963584e028e9aefdd4017d4e2","0ba43b10023c4fe0b61e2f77a4f1e921","6a318b1332254442811d6546577406c9"]},"executionInfo":{"status":"ok","timestamp":1731292776412,"user_tz":180,"elapsed":10894,"user":{"displayName":"Lucas De Fino","userId":"17839929889021431258"}},"outputId":"d089abe3-cf61-409f-c7ab-faa4532b9071"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a77419dbff2b421198a2234e26a379ec"}},"metadata":{}}],"source":["import numpy as np\n","from collections import defaultdict\n","\n","def compute_metrics(logits_and_labels):\n","    logits, labels = logits_and_labels\n","\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    str_labels = []\n","    str_preds = []\n","\n","    for label in labels:\n","        filtered_label = [int(t) for t in label if t != -100]\n","        str_labels.append(filtered_label)\n","\n","    for prediction, label in zip(predictions, labels):\n","        filtered_prediction = [int(p) for p, t in zip(prediction, label) if t != -100]\n","        str_preds.append(filtered_prediction)\n","\n","    entity_metrics = defaultdict(float)\n","\n","    for entity in ['ARCH']:\n","        # entity_metrics[f\"{entity}_precision\"] = precision_calculator(str_preds, str_labels, [label2id[f'B-{entity}'], label2id[f'I-{entity}']])\n","        entity_metrics[f\"{entity}_recall\"] = recall_calculator(str_preds, str_labels, [label2id[f'B-{entity}'], label2id[f'I-{entity}']])\n","        # entity_metrics[f\"{entity}_f1\"] = f1_score_calculator(entity_metrics[f\"{entity}_precision\"], entity_metrics[f\"{entity}_recall\"])\n","\n","    return dict(entity_metrics)\n"]},{"cell_type":"code","source":["!pip install -qq optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YaLsSSIS-_Yr","executionInfo":{"status":"ok","timestamp":1731292781921,"user_tz":180,"elapsed":5524,"user":{"displayName":"Lucas De Fino","userId":"17839929889021431258"}},"outputId":"f5278d04-fcb5-4e05-bc9f-4704730e09fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/362.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/233.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from transformers import Trainer, TrainingArguments, AutoModelForTokenClassification\n","import optuna\n","\n","def model_init():\n","    return AutoModelForTokenClassification.from_pretrained(\n","        checkpoint,\n","        id2label=id2label,\n","        label2id=label2id,\n","        ignore_mismatched_sizes=True\n","    )\n","\n","def hp_space_optuna(trial):\n","    return {\n","        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 6e-05, 6e-04),\n","        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16]),\n","        \"weight_decay\": trial.suggest_loguniform(\"weight_decay\", 0.01, 0.2),\n","        \"warmup_steps\": trial.suggest_int(\"warmup_steps\", 400, 600),\n","        \"lr_scheduler_type\": trial.suggest_categorical(\"lr_scheduler_type\", [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"])\n","    }\n","\n","training_args = TrainingArguments(\n","        output_dir=\"/content/drive/MyDrive/ARCHITECTURE_NER/NER/models/\",\n","        report_to=\"none\",\n","        save_strategy=\"no\",\n","        eval_strategy=\"epoch\",\n","        num_train_epochs = 3,\n","        greater_is_better=True,\n","        load_best_model_at_end=False,\n","        metric_for_best_model=\"ARCH recall\",\n",")\n","\n","trainer = Trainer(\n","    model_init=model_init,\n","    args=training_args,\n","    train_dataset=dataset_dict[\"train\"],\n","    eval_dataset=dataset_dict[\"validation\"],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n","    data_collator=data_collator,\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OF6Y-GRl_EBc","executionInfo":{"status":"ok","timestamp":1731296135957,"user_tz":180,"elapsed":1524,"user":{"displayName":"Lucas De Fino","userId":"17839929889021431258"}},"outputId":"2e2cc6fe-413e-4ca3-e82e-92fa5209a5c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at dslim/distilbert-ner and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([7]) in the model instantiated\n","- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["from optuna.pruners import SuccessiveHalvingPruner\n","\n","best_run = trainer.hyperparameter_search(\n","    hp_space=hp_space_optuna,\n","    direction=\"maximize\",\n","    backend=\"optuna\",\n","    n_trials=30,\n",")\n","\n","print(\"Best hyperparameters found:\", best_run)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"mbcAURtBMZwP","outputId":"83478ad2-39ed-492e-948e-958d387c5752"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-11-11 03:35:37,418] A new study created in memory with name: no-name-f4379c47-7337-4c53-8031-3d39bcd60ee8\n","<ipython-input-23-3bc7f560c235>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 6e-05, 6e-04),\n","<ipython-input-23-3bc7f560c235>:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"weight_decay\": trial.suggest_loguniform(\"weight_decay\", 0.01, 0.2),\n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at dslim/distilbert-ner and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([7]) in the model instantiated\n","- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='870' max='870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [870/870 01:07, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Arch Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.260082</td>\n","      <td>0.528610</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.336600</td>\n","      <td>0.219340</td>\n","      <td>0.663488</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.336600</td>\n","      <td>0.213490</td>\n","      <td>0.690736</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-11 03:36:47,615] Trial 0 finished with value: 0.6907356948228883 and parameters: {'learning_rate': 0.00023201586641598173, 'per_device_train_batch_size': 8, 'weight_decay': 0.10625362317625302, 'warmup_steps': 432, 'lr_scheduler_type': 'polynomial'}. Best is trial 0 with value: 0.6907356948228883.\n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at dslim/distilbert-ner and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([7]) in the model instantiated\n","- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='870' max='870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [870/870 01:04, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Arch Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.280302</td>\n","      <td>0.546322</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.381000</td>\n","      <td>0.234798</td>\n","      <td>0.543597</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.381000</td>\n","      <td>0.216446</td>\n","      <td>0.649864</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-11 03:37:53,652] Trial 1 finished with value: 0.6498637602179836 and parameters: {'learning_rate': 7.734271546334847e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.051902282006642375, 'warmup_steps': 587, 'lr_scheduler_type': 'linear'}. Best is trial 0 with value: 0.6907356948228883.\n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at dslim/distilbert-ner and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([7]) in the model instantiated\n","- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='870' max='870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [870/870 01:03, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Arch Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.265489</td>\n","      <td>0.512262</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.357200</td>\n","      <td>0.231556</td>\n","      <td>0.662125</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.357200</td>\n","      <td>0.217076</td>\n","      <td>0.651226</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-11 03:38:58,661] Trial 2 finished with value: 0.6512261580381471 and parameters: {'learning_rate': 0.00010446633489573423, 'per_device_train_batch_size': 8, 'weight_decay': 0.05905498873986834, 'warmup_steps': 488, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 0 with value: 0.6907356948228883.\n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at dslim/distilbert-ner and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([7]) in the model instantiated\n","- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='870' max='870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [870/870 01:03, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Arch Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.279989</td>\n","      <td>0.553134</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.377300</td>\n","      <td>0.229411</td>\n","      <td>0.547684</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.377300</td>\n","      <td>0.220213</td>\n","      <td>0.643052</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-11 03:40:04,367] Trial 3 finished with value: 0.6430517711171662 and parameters: {'learning_rate': 8.195452105387542e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.04942614729052601, 'warmup_steps': 577, 'lr_scheduler_type': 'polynomial'}. Best is trial 0 with value: 0.6907356948228883.\n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at dslim/distilbert-ner and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([7]) in the model instantiated\n","- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='435' max='435' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [435/435 00:57, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Arch Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.244592</td>\n","      <td>0.599455</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.229417</td>\n","      <td>0.577657</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.245086</td>\n","      <td>0.433243</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-11 03:41:03,071] Trial 4 finished with value: 0.4332425068119891 and parameters: {'learning_rate': 0.0002814842147070491, 'per_device_train_batch_size': 16, 'weight_decay': 0.1316857293540562, 'warmup_steps': 450, 'lr_scheduler_type': 'cosine'}. Best is trial 0 with value: 0.6907356948228883.\n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at dslim/distilbert-ner and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([7]) in the model instantiated\n","- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='145' max='435' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [145/435 00:18 < 00:38, 7.54 it/s, Epoch 1/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Arch Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.248337</td>\n","      <td>0.551771</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-11 03:41:23,851] Trial 5 pruned. \n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at dslim/distilbert-ner and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([7]) in the model instantiated\n","- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='145' max='435' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [145/435 00:18 < 00:38, 7.56 it/s, Epoch 1/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Arch Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.244286</td>\n","      <td>0.512262</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-11 03:41:44,474] Trial 6 pruned. \n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at dslim/distilbert-ner and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([7]) in the model instantiated\n","- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='290' max='870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [290/870 00:21 < 00:42, 13.56 it/s, Epoch 1/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Arch Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.300819</td>\n","      <td>0.346049</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-11 03:42:07,358] Trial 7 pruned. \n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at dslim/distilbert-ner and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([7]) in the model instantiated\n","- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='145' max='435' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [145/435 00:18 < 00:38, 7.56 it/s, Epoch 1/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Arch Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.259612</td>\n","      <td>0.574932</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-11 03:42:27,906] Trial 8 pruned. \n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at dslim/distilbert-ner and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([7]) in the model instantiated\n","- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='145' max='435' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [145/435 00:18 < 00:38, 7.53 it/s, Epoch 1/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Arch Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.301367</td>\n","      <td>0.474114</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-11 03:42:48,555] Trial 9 pruned. \n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at dslim/distilbert-ner and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([7]) in the model instantiated\n","- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='290' max='870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [290/870 00:21 < 00:42, 13.65 it/s, Epoch 1/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Arch Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.275470</td>\n","      <td>0.544959</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-11 03:43:11,811] Trial 10 pruned. \n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at dslim/distilbert-ner and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([7]) in the model instantiated\n","- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='380' max='870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [380/870 00:27 < 00:35, 13.89 it/s, Epoch 1.31/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Arch Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.231033</td>\n","      <td>0.557221</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]}]}